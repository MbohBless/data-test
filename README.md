# LLM-Powered Analytical Intelligence Engine

**MVP Implementation**: FastAPI + LangChain + PostgreSQL + Groq LLMs

Automatically analyze structured data using natural language queries. The system generates SQL, executes queries safely, and returns verified human-readable insights.

---

## ğŸ¯ Overview

This is a production-ready MVP skeleton for an LLM-driven analytical engine that:

- **Accepts natural language queries** â†’ "Show total revenue per month"
- **Generates optimized SQL** using Groq LLMs via LangChain
- **Executes queries safely** with read-only PostgreSQL access
- **Self-evaluates results** and regenerates if needed
- **Returns insights** with visualization recommendations

### Key Features

âœ… **Modular Architecture** - MCP-ready components
âœ… **Safe Execution** - Read-only SQL with validation
âœ… **Self-Correcting** - LLM evaluation and regeneration loop
âœ… **Observable** - Structured logging with request tracing
âœ… **Scalable** - Async operations with connection pooling
âœ… **Type-Safe** - Full type hints and Pydantic validation

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚     POST /api/v1/analyze        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼         â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Schema   â”‚ â”‚  LLM   â”‚ â”‚ Exec   â”‚
â”‚ Manager  â”‚ â”‚Pipelineâ”‚ â”‚ utor   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚           â”‚            â”‚
     â–¼           â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis  â”‚ â”‚ Groq   â”‚ â”‚Postgres  â”‚
â”‚  Cache  â”‚ â”‚  API   â”‚ â”‚    DB    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Workflow

1. **Schema Manager** â†’ Fetches and caches database schema
2. **LLM Pipeline** â†’ Generates SQL from natural language
3. **SQL Verifier** â†’ Validates query safety and correctness
4. **Executor** â†’ Executes read-only SQL
5. **Evaluator** â†’ Checks if results answer the request
6. **Insight Generator** â†’ Creates human-readable summary

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â””â”€â”€ analyze.py          # API endpoints (analyze, schema)
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ cache.py                # Redis caching layer
â”‚   â”‚   â”œâ”€â”€ config.py               # Settings management
â”‚   â”‚   â”œâ”€â”€ evaluator.py            # Query evaluation & regeneration
â”‚   â”‚   â”œâ”€â”€ llm_pipeline.py         # LangChain LLM workflows
â”‚   â”‚   â”œâ”€â”€ schema_manager.py       # Database schema extraction
â”‚   â”‚   â””â”€â”€ executor/
â”‚   â”‚       â””â”€â”€ postgres_executor.py # Safe SQL execution
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py              # Pydantic request/response models
â”‚   â””â”€â”€ main.py                     # FastAPI application entrypoint
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                       # Unit tests
â”‚   â”œâ”€â”€ integration/                # Integration tests
â”‚   â””â”€â”€ conftest.py                 # Pytest fixtures
â”œâ”€â”€ docker-compose.yml              # Local development stack
â”œâ”€â”€ Dockerfile                      # Container definition
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ pyproject.toml                  # Project configuration
â”œâ”€â”€ .env.example                    # Environment template
â””â”€â”€ README.md                       # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Docker & Docker Compose
- Groq API Key ([get one here](https://console.groq.com))

### 1. Clone and Setup

```bash
# Clone repository
git clone <repository-url>
cd llm-analytical-engine

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your Groq API key
# GROQ_API_KEY=your_api_key_here
```

### 3. Start Services

```bash
# Start PostgreSQL and Redis
docker-compose up -d postgres redis

# Wait for services to be healthy
docker-compose ps

# Run migrations (if any)
# (Future: alembic upgrade head)
```

### 4. Run Application

```bash
# Development mode with hot reload
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Or using Docker Compose (full stack)
docker-compose up
```

### 5. Test API

```bash
# Health check
curl http://localhost:8000/health

# Get database schema
curl http://localhost:8000/api/v1/schema

# Submit analysis request
curl -X POST http://localhost:8000/api/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "request": "Show total revenue per month",
    "include_raw_data": true
  }'
```

### 6. View Documentation

Open browser to:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ”§ Configuration

All configuration is managed via environment variables. See `.env.example` for full list.

### Key Settings

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection | `postgresql://...` |
| `REDIS_URL` | Redis connection | `redis://...` |
| `GROQ_API_KEY` | Groq API key | *required* |
| `GROQ_MODEL_NAME` | Model identifier | `mixtral-8x7b-32768` |
| `GROQ_TEMPERATURE` | LLM temperature | `0.1` |
| `MAX_RETRY_ATTEMPTS` | SQL regeneration limit | `2` |
| `READ_ONLY_MODE` | Enforce read-only SQL | `true` |

---

## ğŸ§ª Testing

### Run Tests

```bash
# All tests
pytest

# With coverage
pytest --cov=app --cov-report=html

# Specific test file
pytest tests/unit/test_executor.py

# Integration tests only
pytest tests/integration/
```

### Code Quality

```bash
# Format code
black app/ tests/

# Lint code
ruff check app/ tests/

# Type checking
mypy app/
```

---

## ğŸ“Š API Reference

### POST /api/v1/analyze

Submit natural language analytical query.

**Request:**
```json
{
  "request": "Show total revenue per month",
  "context": {},
  "force_refresh_schema": false,
  "include_raw_data": true
}
```

**Response:**
```json
{
  "insight": "Revenue increased steadily, peaking in July.",
  "key_findings": [
    "Monthly revenue grew 22% on average",
    "July had highest revenue at $142k"
  ],
  "data": [...],
  "visualization_type": "line_chart",
  "sql": "SELECT date_trunc('month', date) AS month, ...",
  "execution_time_ms": 45.2,
  "row_count": 12,
  "evaluation": {...},
  "attempts": 1
}
```

### GET /api/v1/schema

Get database schema summary.

**Response:**
```json
{
  "tables": [...],
  "total_tables": 5,
  "database_name": "analytics",
  "fetched_at": "2024-07-22T10:30:00Z",
  "cached": true
}
```

---

## ğŸ”’ Security

### SQL Execution Safety

- âœ… **Read-only mode** enforced at connection level
- âœ… **Command whitelist** (SELECT, WITH, EXPLAIN only)
- âœ… **SQL injection prevention** via regex and validation
- âœ… **Query timeout** limits execution time
- âœ… **Table name sanitization** prevents path traversal

### Best Practices

1. Always run in `READ_ONLY_MODE=true`
2. Use dedicated read-only database user
3. Limit Groq API key permissions
4. Enable query logging for audit
5. Set appropriate rate limits

---

## ğŸ¯ Development Roadmap

### âœ… Phase 1: MVP Skeleton (Current)

- [x] FastAPI skeleton
- [x] PostgreSQL executor with safety
- [x] LangChain integration (stubs)
- [x] Schema caching
- [x] API endpoints
- [x] Docker setup

### ğŸš§ Phase 2: Implementation (Next 4 weeks)

- [ ] Complete LLM pipeline (SQL generation)
- [ ] Implement evaluation chain
- [ ] Add insight generation
- [ ] Complete test coverage
- [ ] Add logging & observability

### ğŸ“… Phase 3: MCP Integration (Weeks 7-10)

- [ ] Refactor to MCP DataSource Provider
- [ ] Implement MCP Executor interface
- [ ] Add MCP Model Provider wrapper
- [ ] Create MCP Feedback Repository

### ğŸ‰ Phase 4: Production (Weeks 11-12)

- [ ] Performance optimization
- [ ] Security hardening
- [ ] Monitoring & alerting
- [ ] Load testing
- [ ] Deployment automation

---

## ğŸ¤ Contributing

### Code Standards

- Follow PEP 8 style guide
- Add type hints to all functions
- Write docstrings for public APIs
- Maintain test coverage >80%
- Use structured logging

### Commit Messages

```
feat: Add SQL generation chain
fix: Handle NULL values in summary
docs: Update API reference
test: Add executor validation tests
refactor: Extract prompt templates
```

---

## ğŸ“ Implementation Notes

### Function Stubs

Many functions are marked with `raise NotImplementedError()`. These are intentional placeholders for MVP skeleton. Implementation order:

1. **Schema Manager** - `_fetch_schema_from_database()`, `get_sample_rows()`
2. **LLM Pipeline** - All chain methods with actual Groq calls
3. **Evaluator** - `_parse_evaluation_output()`, regeneration logic
4. **Tests** - Complete all `pass` placeholders

### MCP-Ready Design

All core modules expose MCP-compatible interfaces:

- **SchemaManager** â†’ MCP DataSource Provider
- **PostgresExecutor** â†’ MCP Executor
- **LLMPipeline** â†’ MCP Model Provider
- **CacheManager** â†’ MCP Feedback Repository

When migrating to MCP, swap implementations without changing business logic.

---

## ğŸ› Troubleshooting

### Database Connection Failed

```bash
# Check PostgreSQL is running
docker-compose ps postgres

# Check connection string
echo $DATABASE_URL

# Test connection
psql $DATABASE_URL -c "SELECT 1"
```

### Redis Connection Failed

```bash
# Check Redis is running
docker-compose ps redis

# Test connection
redis-cli -u $REDIS_URL ping
```

### LLM API Errors

```bash
# Verify API key
echo $GROQ_API_KEY

# Check API status
curl -H "Authorization: Bearer $GROQ_API_KEY" \
  https://api.groq.com/v1/models
```

---

## ğŸ“§ Contact

For questions or issues, open a GitHub issue.

---

**Built with â¤ï¸ for data-driven teams**
